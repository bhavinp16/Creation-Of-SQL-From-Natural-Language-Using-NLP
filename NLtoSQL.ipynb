{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd014cd6b143582b29907b2988915ba6d818b10a3c3321f78400537caae13f0020c",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "14cd6b143582b29907b2988915ba6d818b10a3c3321f78400537caae13f0020c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "TO DO:\n",
    "X 1) Tokenize the input into list of words \n",
    "X 2) Lemmatize the list of words \n",
    "X 3) Perform POS tagging\n",
    "X 4) Parsed sentence = Parse using regular expressions\n",
    "X 5) If table.attribute âˆˆ Parsed sentence\n",
    "     X  a) Extract them\n",
    "     X  b) Call SQLmap()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['test.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os  \n",
    "\n",
    "print(os.listdir(\"./input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of test set:  (4, 1)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text\n",
       "0  fare price of class2 Shatabdi express from Mum...\n",
       "1  What are the available trains that travel from...\n",
       "2  What is fare for class3 Dadar passenger from D...\n",
       "3  Available trains from Chennai to Mumbai runnin..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fare price of class2 Shatabdi express from Mum...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What are the available trains that travel from...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is fare for class3 Dadar passenger from D...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Available trains from Chennai to Mumbai runnin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "print('Shape of test set: ', test.shape)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Natural Language input is as follows: \n",
      "fare price of class2 Shatabdi express from Mumbai to Goa on 2nd march 2021. \n",
      "\n",
      "Remove Punctuations- \n",
      "fare price of class2 Shatabdi express from Mumbai to Goa on 2nd march 2021 \n",
      "\n",
      "Tokenize The Sentence-\n",
      "['fare', 'price', 'of', 'class2', 'Shatabdi', 'express', 'from', 'Mumbai', 'to', 'Goa', 'on', '2nd', 'march', '2021'] \n",
      "\n",
      "Removing Stop Words-\n",
      "['fare', 'price', 'class2', 'Shatabdi', 'express', 'from', 'Mumbai', 'to', 'Goa', '2nd', 'march', '2021'] \n",
      "\n",
      "Lemmatizing The Tokens-\n",
      "['fare', 'price', 'class2', 'Shatabdi', 'express', 'from', 'Mumbai', 'to', 'Goa', '2nd', 'march', '2021'] \n",
      "\n",
      "POS Tagging Of Lemmatized Tokens- \n",
      "[('fare', 'JJ'), ('price', 'NN'), ('class2', 'NN'), ('Shatabdi', 'NNP'), ('express', 'NN'), ('from', 'IN'), ('Mumbai', 'NNP'), ('to', 'TO'), ('Goa', 'VB'), ('2nd', 'CD'), ('march', 'NN'), ('2021', 'CD')] \n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Natural Language input is as follows: \n",
      "What are the available trains that travel from Delhi to Mumbai on \"1st february 2021\"? \n",
      "\n",
      "Remove Punctuations- \n",
      "What are the available trains that travel from Delhi to Mumbai on 1st february 2021 \n",
      "\n",
      "Tokenize The Sentence-\n",
      "['What', 'are', 'the', 'available', 'trains', 'that', 'travel', 'from', 'Delhi', 'to', 'Mumbai', 'on', '1st', 'february', '2021'] \n",
      "\n",
      "Removing Stop Words-\n",
      "['What', 'available', 'trains', 'travel', 'from', 'Delhi', 'to', 'Mumbai', '1st', 'february', '2021'] \n",
      "\n",
      "Lemmatizing The Tokens-\n",
      "['What', 'available', 'train', 'travel', 'from', 'Delhi', 'to', 'Mumbai', '1st', 'february', '2021'] \n",
      "\n",
      "POS Tagging Of Lemmatized Tokens- \n",
      "[('What', 'WP'), ('available', 'JJ'), ('train', 'VBP'), ('travel', 'NN'), ('from', 'IN'), ('Delhi', 'NNP'), ('to', 'TO'), ('Mumbai', 'NNP'), ('1st', 'CD'), ('february', 'JJ'), ('2021', 'CD')] \n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Natural Language input is as follows: \n",
      "What is fare for class3 Dadar passenger from Dadar to Chiplun on 5th january 2021? \n",
      "\n",
      "Remove Punctuations- \n",
      "What is fare for class3 Dadar passenger from Dadar to Chiplun on 5th january 2021 \n",
      "\n",
      "Tokenize The Sentence-\n",
      "['What', 'is', 'fare', 'for', 'class3', 'Dadar', 'passenger', 'from', 'Dadar', 'to', 'Chiplun', 'on', '5th', 'january', '2021'] \n",
      "\n",
      "Removing Stop Words-\n",
      "['What', 'fare', 'class3', 'Dadar', 'passenger', 'from', 'Dadar', 'to', 'Chiplun', '5th', 'january', '2021'] \n",
      "\n",
      "Lemmatizing The Tokens-\n",
      "['What', 'fare', 'class3', 'Dadar', 'passenger', 'from', 'Dadar', 'to', 'Chiplun', '5th', 'january', '2021'] \n",
      "\n",
      "POS Tagging Of Lemmatized Tokens- \n",
      "[('What', 'WP'), ('fare', 'NN'), ('class3', 'NN'), ('Dadar', 'NNP'), ('passenger', 'NN'), ('from', 'IN'), ('Dadar', 'NNP'), ('to', 'TO'), ('Chiplun', 'VB'), ('5th', 'CD'), ('january', 'JJ'), ('2021', 'CD')] \n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Natural Language input is as follows: \n",
      "Available trains from Chennai to Mumbai running on 21st february 2020. \n",
      "\n",
      "Remove Punctuations- \n",
      "Available trains from Chennai to Mumbai running on 21st february 2020 \n",
      "\n",
      "Tokenize The Sentence-\n",
      "['Available', 'trains', 'from', 'Chennai', 'to', 'Mumbai', 'running', 'on', '21st', 'february', '2020'] \n",
      "\n",
      "Removing Stop Words-\n",
      "['Available', 'trains', 'from', 'Chennai', 'to', 'Mumbai', 'running', '21st', 'february', '2020'] \n",
      "\n",
      "Lemmatizing The Tokens-\n",
      "['Available', 'train', 'from', 'Chennai', 'to', 'Mumbai', 'running', '21st', 'february', '2020'] \n",
      "\n",
      "POS Tagging Of Lemmatized Tokens- \n",
      "[('Available', 'JJ'), ('train', 'NN'), ('from', 'IN'), ('Chennai', 'NNP'), ('to', 'TO'), ('Mumbai', 'NNP'), ('running', 'VBG'), ('21st', 'CD'), ('february', 'JJ'), ('2020', 'CD')] \n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "lemmatizedarr = []\n",
    "POStaggedarr = []\n",
    "modifiedSentence = []\n",
    "\n",
    "# preparing list of stop words\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "exclude_words = set((\"from\", \"to\"))\n",
    "new_stop_words = stop_words.difference(exclude_words)\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "row_count = test.shape[0]\n",
    "\n",
    "# Text Preprocessing\n",
    "for row in range(0, row_count):\n",
    "\n",
    "    # extract sentence from csv file\n",
    "    sentence = test.iloc[row]['text']\n",
    "    print(\"\\nNatural Language input is as follows: \")\n",
    "    print(sentence, \"\\n\")\n",
    "\n",
    "    # remove punctuation\n",
    "    print(\"Remove Punctuations- \")\n",
    "    sentence = sentence.translate(sentence.maketrans(\"\",\"\",string.punctuation))\n",
    "    print(sentence, \"\\n\")\n",
    "    modifiedSentence.append(sentence)\n",
    "\n",
    "    # tokenize the sentence\n",
    "    print(\"Tokenize The Sentence-\")\n",
    "    sentence = word_tokenize(sentence)\n",
    "    print(sentence, \"\\n\")\n",
    "\n",
    "    # removing stop words\n",
    "    print(\"Removing Stop Words-\")\n",
    "    words_in_sentence = [word for word in sentence if not word in new_stop_words]\n",
    "    print(words_in_sentence, \"\\n\")\n",
    "\n",
    "    # lemmatizing the tokens\n",
    "    print(\"Lemmatizing The Tokens-\")\n",
    "    for index,word in enumerate(words_in_sentence):\n",
    "        words_in_sentence[index] = lemmatizer.lemmatize(word)\n",
    "    print(words_in_sentence, \"\\n\")\n",
    "    lemmatizedarr.append(words_in_sentence)\n",
    "\n",
    "    # POS tagging of lemmatized tokens\n",
    "    tagged = nltk.pos_tag(words_in_sentence)\n",
    "    print(\"POS Tagging Of Lemmatized Tokens- \")\n",
    "    print(tagged, \"\\n\")\n",
    "    POStaggedarr.append(tagged)\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'5/1/2021'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Regular expressions for extraction of attributes from the sentence\n",
    "\n",
    "\n",
    "# Extract class of fare done\n",
    "def Fare_Identifier(sentence):\n",
    "    fare = re.search('fare' , sentence)\n",
    "    if fare:\n",
    "        d = re.search('class[123]', sentence)\n",
    "        return d[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "# Extract train name done\n",
    "def Train_Name_Identifier(sentence):\n",
    "    d = re.search('([^ \\r\\n]+) express | ([^ \\r\\n]+) mail | ([^ \\r\\n]+) passenger', sentence)\n",
    "    if d:\n",
    "        return d[0]\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract source and destination Using Pos tagged list \n",
    "def Source_Destination_Identifier(posarr):\n",
    "    source = \"\"\n",
    "    destination = \"\"\n",
    "    nextflagsource = False\n",
    "    nextflagdestination = False\n",
    "\n",
    "    for i in posarr:\n",
    "        if nextflagsource:\n",
    "            source = i[0]\n",
    "            nextflagsource = False\n",
    "        if nextflagdestination:\n",
    "            destination = i[0]\n",
    "            nextflagdestination = False\n",
    "\n",
    "        if i[1] == \"IN\":\n",
    "            nextflagsource = True\n",
    "        if i[1] == \"TO\":\n",
    "            nextflagdestination = True\n",
    "\n",
    "    return source, destination\n",
    "\n",
    "\n",
    "# Extract date\n",
    "def Date_Identifier(sentence):\n",
    "    day = None\n",
    "    month = None\n",
    "    year = None\n",
    "\n",
    "    # extracting word before and the word of month \n",
    "    day_month = re.search(r\"([^ \\r\\n]+) (jan+)| ([^ \\r\\n]+) (feb+)| ([^ \\r\\n]+) (mar+)| ([^ \\r\\n]+)(apr+)| ([^ \\r\\n]+)(may+)| ([^ \\r\\n]+)(jun+)| ([^ \\r\\n]+)(jul+)| ([^ \\r\\n]+)(aug+)| ([^ \\r\\n]+)(sep+)| ([^ \\r\\n]+)(oct+)| ([^ \\r\\n]+)(nov+)| ([^ \\r\\n]+)(dec+)\", sentence)\n",
    "    \n",
    "    if day_month:\n",
    "        #extracting day from day and month\n",
    "        day = re.search(r'[0123456789]',day_month[0])[0]\n",
    "        month = re.search(r\"(jan+)|(feb+)|(mar+)|(apr+)|(may+)|(jun+)|(jul+)|(aug+)|(sep+)|(oct+)|(nov+)|(dec+)\", day_month[0])[0]\n",
    "   \n",
    "    # extracting word after and the word month\n",
    "    d = re.search(r\"(january) (\\w+)| (february) (\\w+)| (march) (\\w+)| (april) (\\w+)| (may) (\\w+)| (june) (\\w+)| (july) (\\w+)| (august) (\\w+)| (september) (\\w+)| (october) (\\w+)| (november) (\\w+)| (december) (\\w+)\", sentence, re.I)\n",
    "    \n",
    "    if d:\n",
    "        #extracting year from month and year\n",
    "        year = re.search(r'[0123456789]+',d[0])[0]\n",
    "\n",
    "    m_np = 0\n",
    "    if month == \"jan\":\n",
    "        m_np = 1\n",
    "    elif month == \"feb\":\n",
    "        m_np = 2\n",
    "    elif month == \"mar\":\n",
    "        m_np = 3\n",
    "    elif month == \"apr\":\n",
    "        m_np = 4\n",
    "    elif month == \"may\":\n",
    "        m_np = 5\n",
    "    elif month == \"jun\":\n",
    "        m_np = 6\n",
    "    elif month == \"jul\":\n",
    "        m_np = 7\n",
    "    elif month == \"aug\":\n",
    "        m_np = 8\n",
    "    elif month == \"sep\":\n",
    "        m_np = 9\n",
    "    elif month == \"oct\":\n",
    "        m_np = 10\n",
    "    elif month == \"nov\":\n",
    "        m_np = 11\n",
    "    else:\n",
    "        m_np = 12\n",
    "\n",
    "    return day + \"/\" + str(m_np) + \"/\" + year\n",
    "\n",
    "\n",
    "Date_Identifier(modifiedSentence[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Query 0: \n\nSELECT fare_class2 FROM railways.train WHERE train_name = Shatabdi express  source_stn = Mumbai destination_stn = Goa date = 2/3/2021\n\n\n\nQuery 1: \n\nSELECT train_no, train_name FROM railways.train WHERE  source_stn = Delhi destination_stn = Mumbai date = 1/2/2021\n\n\n\nQuery 2: \n\nSELECT fare_class3 FROM railways.train WHERE train_name =  Dadar passenger source_stn = Dadar destination_stn = Chiplun date = 5/1/2021\n\n\n\nQuery 3: \n\nSELECT train_no, train_name FROM railways.train WHERE  source_stn = Chennai destination_stn = Mumbai date = 2/2/2020\n\n\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# function for query formation from extracted attributes\n",
    "def sql_map(value, source, destination, date, fare):\n",
    "    query= \"SELECT \"\n",
    "    if fare:\n",
    "        query = query + \"fare_\" + fare + \" \"\n",
    "    else:\n",
    "        query = query + \"train_no, \" + \"train_name \"\n",
    "    query = query + \"FROM railways.train WHERE \"\n",
    "    if value:\n",
    "        query = query + \"train_name = \" + value\n",
    "    if source and destination:\n",
    "        query = query + \" source_stn = \" + source + \" destination_stn = \" + destination\n",
    "    if date:\n",
    "        query = query + \" date = \" + date\n",
    "    \n",
    "    print(query)\n",
    "\n",
    "\n",
    "# driver code \n",
    "for row in range(0, row_count):\n",
    "    value = Train_Name_Identifier(modifiedSentence[row])\n",
    "    source, destination = Source_Destination_Identifier(POStaggedarr[row])\n",
    "    date = Date_Identifier(modifiedSentence[row])\n",
    "    fare = Fare_Identifier(modifiedSentence[row])\n",
    "    print(\"Query \" + str(row) + \": \\n\")\n",
    "    sql_map(value, source, destination, date, fare)    \n",
    "    print('\\n\\n')\n",
    "\n"
   ]
  }
 ]
}